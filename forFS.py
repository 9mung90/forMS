# -*- coding: utf-8 -*-
import sys
import re
import torch
import logging

# íŠ¸ëœìŠ¤í¬ë¨¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ (Hugging Face)
from transformers import AutoTokenizer, BertForSequenceClassification

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸° (ë°ëª¨ í™”ë©´ì„ ê¹”ë”í•˜ê²Œ í•˜ê¸° ìœ„í•¨)
logging.getLogger("transformers").setLevel(logging.ERROR)

# =============================================================================
# 1. ì„¤ì • ë° ë°ì´í„° (ìš•ì„¤ ì‚¬ì „, í”¼ë“œë°± ë©”ì‹œì§€)
# =============================================================================

# [ì„¤ì •] ì‚¬ìš©í•  ëª¨ë¸ (Smilegate AIì˜ UnSmile ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸)
MODEL_NAME = "smilegate-ai/kor_unsmile"

# [ë°ì´í„°] í˜ì˜¤ ìœ í˜• ë¼ë²¨ (ëª¨ë¸ ì¶œë ¥ ìˆœì„œì™€ ë™ì¼í•´ì•¼ í•¨)
LABELS = [
    "ì—¬ì„±/ê°€ì¡±", "ë‚¨ì„±", "ì„±ì†Œìˆ˜ì", "ì¸ì¢…/êµ­ì ",
    "ì—°ë ¹", "ì§€ì—­", "ì¢…êµ", "ê¸°íƒ€ í˜ì˜¤",
    "ì•…í”Œ/ìš•ì„¤", "clean"
]

# [ë°ì´í„°] ìš•ì„¤/ë¹„í•˜ í‘œí˜„ ì¹˜í™˜ ì‚¬ì „ (Badword Masking)
# UnSmile ë°ì´í„°ì…‹ì˜ 10ê°œ ë¼ë²¨ì„ ì»¤ë²„í•˜ëŠ” 200ì—¬ ê°œì˜ ë¹„ì†ì–´/í˜ì˜¤ í‘œí˜„ ë§¤í•‘
# (í‚¤: ë¹„ì†ì–´ / ê°’: ìˆœí™”ëœ ì¤‘ë¦½ í‘œí˜„)

BADWORD_DICT = {
    # ==========================================
    # 1. ê°ì •ì  ìš•ì„¤ & ë¹„ì†ì–´ (General Profanity) - ì´ˆì„± ë³€í˜• í¬í•¨
    # ==========================================
    "ì‹œë°œ": "ì´ëŸ°", "ì”¨ë°œ": "ì´ëŸ°", "ã……ã…‚": "ì´ëŸ°", "ã…†ã…‚": "ì´ëŸ°", "ì‰¬ë°œ": "ì´ëŸ°", "ìŠˆë°œ": "ì´ëŸ°", "ìŠ¤ë²Œ": "ì´ëŸ°",
    "ê°œìƒˆë¼": "ë‚˜ìœ ì‚¬ëŒ", "ê°œì„¸ë¼": "ë‚˜ìœ ì‚¬ëŒ", "ê°œìƒ‰ê¸°": "ë‚˜ìœ ì‚¬ëŒ", "ê²¬ìƒˆë¼": "ë‚˜ìœ ì‚¬ëŒ",
    "ìƒˆë¼": "ì‚¬ëŒ", "ìƒ‰ê¸°": "ì‚¬ëŒ", "ì‰ë¼": "ì‚¬ëŒ", "ì‰‘": "ì‚¬ëŒ",
    "êº¼ì ¸": "ìë¦¬ë¥¼ ë¹„ì¼œ ì¤˜", "ë‹¥ì³": "ì¡°ìš©íˆ í•´ ì¤˜", "ì•„ê°€ë¦¬": "ì…", "ì•„ê°ˆì°½": "ì…",
    "ì¢†ê°™ì€": "ë§¤ìš° í˜ë“ ", "ì¢†ê°™": "í˜ë“ ", "ì¡±ê°™": "í˜ë“ ", "ã…ˆê°™": "í˜ë“ ",
    "ì¢†": "ì•„", "ã…ˆ": "ì•„",
    "ì¡´ë‚˜": "ë§¤ìš°", "ì¡¸ë¼": "ì •ë§", "ì¡´ë‚´": "ë§¤ìš°", "ì¡°ì˜¨ë‚˜": "ì•„ì£¼", "ã…ˆã„´": "ë§¤ìš°",
    "ë¯¸ì¹œ": "ìƒì‹ì„ ë²—ì–´ë‚œ", "ë¯¸ì³¤": "ìƒì‹ì„ ë²—ì–´ë‚œ",
    "ì—¼ë³‘": "ì†ìƒí•œ ì¼", "ì˜˜ë³‘": "ì†ìƒí•œ ì¼", "ì  ì¥": "ì´ëŸ°", "ì œê¸°ë„": "ì´ëŸ°", "ìœ¡ì‹œë„": "ì´ëŸ°",
    "ë‹ˆë¯¸": "ì´ëŸ°", "ì§€ë„": "ì†Œë€", "ã…ˆã„¹": "ì†Œë€",
    "ì”¹": "ë§¤ìš°", "ì‹­": "ë§¤ìš°",  # ì ‘ë‘ì–´ë¡œ ì“°ì¼ ë•Œ
    "ë³‘í¬": "ì‹¤ìˆ˜", "ì‹œë§": "ì‹¤íŒ¨", "ë§í• ": "ì†ìƒí•œ", "ë’ˆì ¸": "ì‚¬ë¼ì ¸", "ë’¤ì ¸": "ì‚¬ë¼ì ¸",
    "ì—¿ë¨¹ì–´": "ê±°ì ˆí• ê²Œ", "ã…—": "ê±°ì ˆ",
    "ì•„êµ¬ì°½":"ì…","ì‘ì‘":"ê·¸ë§Œ","ì²˜ë¨¹":"ë¨¹",

    # =======================================
    # 2. ì¸ì‹ ê³µê²© & ëŠ¥ë ¥/ì™¸ëª¨ ë¹„í•˜ (Personal Attacks)
    # ==========================================
    "ë³‘ì‹ ": "ì•„í”ˆ ì‚¬ëŒ", "ë³‘1ì‹ ": "ì•„í”ˆ ì‚¬ëŒ", "ë¸…ì‹ ": "ì•„í”ˆ ì‚¬ëŒ", "ë¹™ì‹ ": "ì•„í”ˆ ì‚¬ëŒ", "ã…‚ã……": "ì‚¬ëŒ",
    "ë¯¸ì¹œë†ˆ": "ì‚¬ëŒ", "ë¯¸ì¹œë…„": "ì‚¬ëŒ", "ë¯¸ì¹œX": "ì‚¬ëŒ",
    "ì“°ë ˆê¸°": "ì˜ˆì˜ ì—†ëŠ” ì‚¬ëŒ", "ì“°ë ˆê¸°ê°™ì€": "ì˜ˆì˜ ì—†ëŠ”",
    "ê±¸ë ˆ": "ì‚¬ëŒ", "ê°ˆë³´": "ì‚¬ëŒ", "ì°½ë…€": "ì„±ë§¤ë§¤ ì¢…ì‚¬ì", "ì°½ë‚¨": "ì„±ë§¤ë§¤ ì¢…ì‚¬ì",
    "í˜¸êµ¬": "ì°©í•œ ì‚¬ëŒ", "í‘ìš°": "ì°©í•œ ì‚¬ëŒ",
    "ì°ë”°": "ì¹œêµ¬", "ì°": "ì¹œêµ¬", "ì™•ë”°": "ì†Œì™¸ëœ ì¹œêµ¬", "ì•„ì‹¸": "ë‚´í–¥ì ì¸ ì¹œêµ¬",
    "ë¼ì§€": "ì²´ê²©ì´ ìˆëŠ” ë¶„", "ë¼ì§€ìƒˆë¼": "ì²´ê²©ì´ ìˆëŠ” ë¶„", "íŒŒì˜¤í›„": "ì²´ê²©ì´ ìˆëŠ” ë¶„", "ëš±ë•¡ì´": "ì²´ê²©ì´ ìˆëŠ” ë¶„",
    "ë©¸ì¹˜": "ë§ˆë¥¸ ë¶„",
    "ëŒ€ê°€ë¦¬": "ë¨¸ë¦¬", "ëŒ€ê°ˆë¹¡": "ë¨¸ë¦¬", "ëšë°°ê¸°": "ë¨¸ë¦¬",
    "ë…„": "ë¶„", "ë†ˆ": "ë¶„", "ë†ˆë…„": "ë¶„ë“¤",
    "ê´€ì¢…": "ê´€ì‹¬ì´ í•„ìš”í•œ ë¶„", "ëŠê¸ˆ": "ë¶€ëª¨ë‹˜",
    "ë¬´ë‡Œ": "ìƒê°ì´ ë¶€ì¡±í•œ", "ë¹¡ëŒ€ê°€ë¦¬": "ìƒê°ì´ ë¶€ì¡±í•œ",
    "ì— ì°½": "ì ˆëŒ€", "ì— ìƒ": "ì–´ë ¤ìš´ ì‚¶",

    # ==========================================ã…Œ
    # 3. ì—¬ì„±/ê°€ì¡± í˜ì˜¤ (Women & Family)
    # ==========================================
    "ê¹€ì¹˜ë…€": "ì—¬ì„±", "ëœì¥ë…€": "ì—¬ì„±", "ê¹€ì—¬ì‚¬": "ì—¬ì„± ìš´ì „ì",
    "ë§˜ì¶©": "ì–´ë¨¸ë‹ˆ", "í”¼ì‹¸ê°œ": "ì—¬ì„±", "ìƒíë…€": "ì—¬ì„±", "í•œë…€": "í•œêµ­ ì—¬ì„±",
    "ëŠê¸ˆë§ˆ": "ì–´ë¨¸ë‹ˆ", "ë‹ˆì• ë¯¸": "ì–´ë¨¸ë‹ˆ", "ì• ë¯¸": "ì–´ë¨¸ë‹ˆ", "ëŠê°œë¹„": "ì•„ë²„ì§€", "ì• ë¹„": "ì•„ë²„ì§€",
    "ã„´ã…‡ã…": "ì–´ë¨¸ë‹ˆ", "íŒ¨ë“œë¦½": "ê°€ì¡± ë¹„í•˜", "ì°½ë…„": "ì—¬ì„±",
    "ì—¬í¸ë„¤": "ì•„ë‚´", "ë§ˆëˆ„ë¼": "ì•„ë‚´", "ê³„ì§‘": "ì—¬ì„±", "ê°€ì‹œë‚˜": "ì—¬ì„±",
    "ë³´ì „ê¹¨": "ì—¬ì„± ë¹„í•˜", "í˜œì§€": "ì—¬ì„± ê²Œì´ë¨¸",

    # ==========================================
    # 4. ë‚¨ì„± í˜ì˜¤ (Men)
    # ==========================================
    "í•œë‚¨": "í•œêµ­ ë‚¨ì„±", "í•œë‚¨ì¶©": "í•œêµ­ ë‚¨ì„±", "ì†Œì¶”": "ë‚¨ì„±", "6.9": "ë‚¨ì„±",
    "ëƒ„ì ¸": "ë‚¨ì", "ê°œì €ì”¨": "ì•„ì €ì”¨", "ì¬ê¸°í•´": "ì‚¬ë¼ì ¸", "ì¬ê¸°": "ì‚¬ë¼ì ¸",
    "êµ°ë¬´ìƒˆ": "êµ°í•„ì", "ê½ì¹˜ë‚¨": "ë‚¨ì„±", "ìˆ¨ì‰´í•œ": "ë‚¨ì„± ë¹„í•˜",

    # ==========================================
    # 5. ì—°ë ¹ í˜ì˜¤ (Age - Old & Young)
    # ==========================================
    "í‹€ë”±": "ì–´ë¥´ì‹ ", "í‹€ë”±ì¶©": "ì–´ë¥´ì‹ ", "ì—°ê¸ˆì¶©": "ë…¸ë…„ì¸µ", "í• ë§¤ë¯¸": "í• ë¨¸ë‹ˆ", "ë…¸ì¸ë„¤": "ì–´ë¥´ì‹ ",
    "í‹€": "ì–´ë¥´ì‹ ", "ê²½ë¡œë‹¹": "ì–´ë¥´ì‹ ë“¤",
    "ê¸‰ì‹ì¶©": "í•™ìƒ", "ê¸‰ì‹": "í•™ìƒ", "ì¼ë¯¼ì´": "ì–´ë¦°ì´", "ì¼ë¯¼": "ì–´ë¦°ì´",
    "ì´ˆë”©": "ì´ˆë“±í•™ìƒ", "ì¤‘ë”©": "ì¤‘í•™ìƒ", "ê³ ë”©": "ê³ ë“±í•™ìƒ",
    "í•™ì‹": "ëŒ€í•™ìƒ", "í•™ì‹ì¶©": "ëŒ€í•™ìƒ", "ê¼°ëŒ€": "ì¡°ì–¸ì",

    # ==========================================
    # 6. ì§€ì—­ í˜ì˜¤ (Region)
    # ==========================================
    "í™ì–´": "ì „ë¼ë„ë¯¼", "í™ì–´ì‰ë¦¬": "ì „ë¼ë„ë¯¼", "ì „ë¼ë””ì–¸": "ì „ë¼ë„ë¯¼", "ê¹Œë³´ì „": "ì „ë¼ë„ë¯¼", "ì•Œë³´ì¹ ": "ì „ë¼ë„ë¯¼",
    "ìŒë„": "ê²½ìƒë„ë¯¼", "ê°œìŒë„": "ê²½ìƒë„ë¯¼", "ê³¼ë©”ê¸°": "ê²½ìƒë„ë¯¼", "í‰ë…¸": "ê²½ìƒë„ë¯¼",
    "ë©ì²­ë„": "ì¶©ì²­ë„ë¯¼", "ê°ìêµ­": "ê°•ì›ë„ë¯¼",
    "ì„¤ë¼ë””ì–¸": "ì„œìš¸ ì‹œë¯¼", "ì´Œë†ˆ": "ì§€ë°© ë¶„", "ì‹œê³¨ ì´Œë†ˆ": "ì§€ë°© ë¶„",

    # ==========================================
    # 7. ì¸ì¢…/êµ­ì  í˜ì˜¤ (Race & Nationality)
    # ==========================================
    "ì§±ê¹¨": "ì¤‘êµ­ì¸", "ì§±ê¼´ë¼": "ì¤‘êµ­ì¸", "ì°©ì§±ì£½ì§±": "ì¤‘êµ­ì¸ ë¹„í•˜", "ë–¼ë†ˆ": "ì¤‘êµ­ì¸",
    "ìª½ë°œì´": "ì¼ë³¸ì¸", "ìª½ë°”ë¦¬": "ì¼ë³¸ì¸", "ì›ìˆ­ì´": "ì¼ë³¸ì¸", "ì™œë†ˆ": "ì¼ë³¸ì¸",
    "ë˜¥ë‚¨ì•„": "ë™ë‚¨ì•„ì¸", "ì™¸ë…¸ì": "ì™¸êµ­ì¸ ê·¼ë¡œì",
    "í‘í˜•": "í‘ì¸", "ê²€ë‘¥ì´": "í‘ì¸", "ê¹œë‘¥ì´": "í‘ì¸", "ë‹ˆê·¸ë¡œ": "í‘ì¸",
    "ì–‘í‚¤": "ì„œì–‘ì¸", "ì½”ìŸì´": "ì„œì–‘ì¸", "ë°±ë§ˆ": "ë°±ì¸ ì—¬ì„±",
    "ì¡°ì„ ì¡±": "ì¤‘êµ­ ë™í¬", "ë¹µì¦ˆ": "í•œêµ­ì¸",

    # ==========================================
    # 8. ì„±ì†Œìˆ˜ì í˜ì˜¤ (LGBTQ+)
    # ==========================================
    "ë˜¥ê¼¬ì¶©": "ì„±ì†Œìˆ˜ì", "ê²Œì´ìƒˆë¼": "ì„±ì†Œìˆ˜ì", "í˜¸ëª¨": "ì„±ì†Œìˆ˜ì", "ê²Œì´": "ì„±ì†Œìˆ˜ì",
    "ë ˆì¦ˆ": "ì„±ì†Œìˆ˜ì", "ë ˆì¦ˆë…„": "ì„±ì†Œìˆ˜ì", "íŠ¸ì  ": "íŠ¸ëœìŠ¤ì  ë”",
    "ì  ë”ì¶©": "ì„±ì†Œìˆ˜ì", "pcì¶©": "ë‹¤ì–‘ì„± ì¡´ì¤‘ì", "ë¶•íƒ": "ì„±ì†Œìˆ˜ì ë¹„í•˜",

    # ==========================================
    # 9. ì¢…êµ ë° ê¸°íƒ€ í˜ì˜¤ (Religion & Others)
    # ==========================================
    "ê°œë…": "ê¸°ë…êµì¸", "ê°œë…êµ": "ê¸°ë…êµ", "ë¨¹ì‚¬": "ëª©ì‚¬", "ì˜ˆìˆ˜ìŸì´": "ê¸°ë…êµì¸",
    "ë•¡ì¤‘": "ìŠ¤ë‹˜", "ì¤‘ë†ˆ": "ìŠ¤ë‹˜",
    "ì• ì": "ì¥ì• ì¸", "ì¥ì• ì¸": "ëª¸ì´ ë¶ˆí¸í•œ ë¶„", "ë³‘ì‹ ìƒˆë¼": "ë‚˜ìœ ì‚¬ëŒ", "ì¥ì• ": "ë¶ˆí¸í•¨",
    "ê¸°ë ˆê¸°": "ê¸°ì", "ê²¬ì°°": "ê²½ì°°", "ì§­ìƒˆ": "ê²½ì°°", "ê³µë¬´ìƒˆ": "ê³µë¬´ì›",
    "ë§˜ì¶©": "ì–´ë¨¸ë‹ˆ", "ì•±ì¶©": "ì•„ë²„ì§€", "ë²Œë ˆ": "ì‚¬ëŒ", "ì¶©": "ì‚¬ëŒ",
    "ì¢Œë¹¨": "ì§„ë³´ ì„±í–¥", "ë¹¨ê°±ì´": "ì§„ë³´ ì„±í–¥", "í™ì–´": "ì§„ë³´ ì„±í–¥", "ë‹¬ì°½": "ì§€ì§€ì", "ëŒ€ê¹¨ë¬¸": "ì§€ì§€ì",
    "ìˆ˜ê¼´": "ë³´ìˆ˜ ì„±í–¥", "í†µêµ¬ì´": "ë³´ìˆ˜ ì„±í–¥", "í‹€ë”±": "ë³´ìˆ˜ ì„±í–¥", "í† ì°©ì™œêµ¬": "ë³´ìˆ˜ ì„±í–¥",
    "ì¼ë² ": "ì»¤ë®¤ë‹ˆí‹° ìœ ì €", "ì¼ë² ì¶©": "ì»¤ë®¤ë‹ˆí‹° ìœ ì €", "ë©”ê°ˆ": "ì»¤ë®¤ë‹ˆí‹° ìœ ì €", "í˜ë¯¸ì¶©": "í˜ë¯¸ë‹ˆìŠ¤íŠ¸",
    "ì•ˆê²½ì—¬ë“œë¦„ë¼ì§€": "ì™¸ëª¨ ë¹„í•˜", "ì˜¤íƒ€ì¿ ": "ë§¤ë‹ˆì•„", "ì”¹ë•": "ë§¤ë‹ˆì•„", "ì‹­ë•": "ë§¤ë‹ˆì•„"
}

# [ë°ì´í„°] í˜ì˜¤ ìœ í˜•ë³„ ìˆœí™” ê°€ì´ë“œ (Rewrite Suggestion)
FEEDBACK_DICT = {
    "ì—¬ì„±/ê°€ì¡±": "ì„±ë³„ì´ë‚˜ ê°€ì¡± ì „ì²´ë¥¼ ì¼ë°˜í™”í•˜ê¸°ë³´ë‹¤ëŠ”, íŠ¹ì • ìƒí™©ì´ë‚˜ í–‰ë™ì— ëŒ€í•´ ì„¤ëª…í•˜ëŠ” í‘œí˜„ì´ ì¢‹ìŠµë‹ˆë‹¤.",
    "ë‚¨ì„±": "íŠ¹ì • ì„±ë³„ì„ ì‹¸ì¡ì•„ ë¹„ë‚œí•˜ê¸°ë³´ë‹¤ëŠ”, ë¬¸ì œë¼ê³  ëŠë‚€ í–‰ë™ì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ì´ì•¼ê¸°í•´ë³´ì„¸ìš”.",
    "ì„±ì†Œìˆ˜ì": "ì„±ì  ì§€í–¥ì´ë‚˜ ì •ì²´ì„±ì„ ê³µê²©í•˜ê¸°ë³´ë‹¤, ì„œë¡œì˜ ë‹¤ë¦„ì„ ì¸ì •í•˜ê³  ì¡´ì¤‘í•˜ëŠ” í‘œí˜„ì„ ì‚¬ìš©í•´ë³´ì„¸ìš”.",
    "ì¸ì¢…/êµ­ì ": "êµ­ì ì´ë‚˜ ì¸ì¢… ì „ì²´ë¥¼ ë¹„í•˜í•˜ì§€ ë§ê³ , ê°ê´€ì ì¸ ìƒí™©ì´ë‚˜ ì œë„ë¥¼ ì„¤ëª…í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.",
    "ì—°ë ¹": "ë‚˜ì´ë§Œì„ ì´ìœ ë¡œ ë¹„í•˜í•˜ê¸°ë³´ë‹¤ëŠ”, ì„¸ëŒ€ ê°„ ì°¨ì´ë¥¼ ì´í•´í•˜ë ¤ëŠ” íƒœë„ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
    "ì§€ì—­": "íŠ¹ì • ì§€ì—­ ì‚¬ëŒ ì „ì²´ë¥¼ ë§¤ë„í•˜ê¸°ë³´ë‹¤ëŠ”, ë³¸ì¸ì´ ê²ªì€ ê°œë³„ì ì¸ ê²½í—˜ìœ¼ë¡œ êµ­í•œí•˜ì—¬ í‘œí˜„í•´ ì£¼ì„¸ìš”.",
    "ì¢…êµ": "ì‹ ì•™ ìì²´ë¥¼ ê³µê²©í•˜ê¸°ë³´ë‹¤ëŠ”, ë™ì˜í•˜ì§€ ì•ŠëŠ” ì˜ê²¬ì— ëŒ€í•´ ë…¼ë¦¬ì ìœ¼ë¡œ ë°˜ë°•í•´ ë³´ì„¸ìš”.",
    "ê¸°íƒ€ í˜ì˜¤": "ì§‘ë‹¨ ì „ì²´ë¥¼ í–¥í•œ í˜ì˜¤ í‘œí˜„ì€ ì§€ì–‘í•˜ê³ , êµ¬ì²´ì ì¸ ì‚¬ì‹¤ì— ê¸°ë°˜í•´ ê±´ì „í•˜ê²Œ ëŒ€í™”í•´ ì£¼ì„¸ìš”.",
    "ì•…í”Œ/ìš•ì„¤": "ê°•í•œ ê°ì •ì´ ë“¤ ë•ŒëŠ” ì ì‹œ ì§„ì •í•˜ê³ , ìš•ì„¤ ëŒ€ì‹  ë¶ˆë§Œ ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì ì–´ë³´ì„¸ìš”.",
    "clean": "ìƒëŒ€ë¥¼ ì¡´ì¤‘í•˜ëŠ” í‘œí˜„ì…ë‹ˆë‹¤. ì§€ê¸ˆì²˜ëŸ¼ ê±´ê°•í•œ ì˜¨ë¼ì¸ ì†Œí†µì„ ì´ì–´ê°€ ì£¼ì„¸ìš”."
}


# ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼ (ì¹˜í™˜ ì†ë„ í–¥ìƒ)
def build_badword_patterns(badword_dict):
    patterns = {}
    for bad in badword_dict.keys():
        # ìš•ì„¤ ë’¤ì— ë¶™ëŠ” ì¡°ì‚¬(ì´, ê°€, ì€, ëŠ” ë“±)ë¥¼ ìœ ì—°í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì •ê·œì‹
        escaped = re.escape(bad)
        pattern = re.compile(rf"({escaped})([ì´ê°€ì€ëŠ”ì„ë¥¼]*)")
        patterns[bad] = pattern
    return patterns


BADWORD_PATTERNS = build_badword_patterns(BADWORD_DICT)


# =============================================================================
# 2. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ (ëª¨ë¸ ë¡œë“œ, ì „ì²˜ë¦¬, ì˜ˆì¸¡)
# =============================================================================

def load_system():
    """ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    print("\n[ì‹œìŠ¤í…œ] AI ëª¨ë¸ì„ ë¡œë”© ì¤‘ì…ë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”)")
    device = "cuda" if torch.cuda.is_available() else "cpu"

    try:
        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
        model = BertForSequenceClassification.from_pretrained(MODEL_NAME)
        model.to(device)
        model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
        print(f"[ì‹œìŠ¤í…œ] ëª¨ë¸ ë¡œë”© ì™„ë£Œ! (ê°€ì† ì¥ì¹˜: {device})")
        return model, tokenizer, device
    except Exception as e:
        print(f"\n[ì˜¤ë¥˜] ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\nì›ì¸: {e}")
        print("ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ 'pip install transformers torch' ì„¤ì¹˜ ì—¬ë¶€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        sys.exit(1)


def replace_badwords_func(text):
    """ë¬¸ì¥ ë‚´ ìš•ì„¤ì„ ìˆœí™”ëœ í‘œí˜„ìœ¼ë¡œ ì¹˜í™˜í•©ë‹ˆë‹¤."""
    cleaned_text = text
    logs = []

    # ê¸´ ë‹¨ì–´ë¶€í„° ì¹˜í™˜í•˜ê¸° ìœ„í•´ ì •ë ¬ (ì˜ˆ: 'ê°œ'ë³´ë‹¤ 'ê°œìƒˆë¼'ë¥¼ ë¨¼ì € ì°¾ìŒ)
    sorted_keys = sorted(BADWORD_DICT.keys(), key=len, reverse=True)

    for bad in sorted_keys:
        pattern = BADWORD_PATTERNS[bad]
        replacement = BADWORD_DICT[bad]

        def _sub_func(match):
            word = match.group(1)
            tail = match.group(2) or ""  # ì¡°ì‚¬
            # ë¡œê·¸ì— ê¸°ë¡ (ì˜ˆ: 'ë³‘ì‹ ' -> 'ì‚¬ëŒ')
            logs.append(f"'{word}' -> '{replacement}'")
            return replacement + tail

        cleaned_text, _ = pattern.subn(_sub_func, cleaned_text)

    return cleaned_text, logs


def analyze_sentence(text, model, tokenizer, device):
    """ë¬¸ì¥ì„ ë¶„ì„í•˜ì—¬ í˜ì˜¤ ìœ í˜•, ìˆœí™” ë¬¸ì¥, í”¼ë“œë°±ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""

    # 1. ëª¨ë¸ ì˜ˆì¸¡ (Inference)
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        # ë¡œì§“(Logits)ì„ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ 0~1 ì‚¬ì´ í™•ë¥ ê°’ ë„ì¶œ
        probs = torch.sigmoid(outputs.logits[0])

    probs_list = probs.cpu().tolist()

    # 2. ì„ê³„ê°’(Threshold) 0.5 ì´ìƒì¸ ë¼ë²¨ ì¶”ì¶œ
    detected_labels = []
    label_scores = {}  # í”¼ë“œë°± ì„ ì •ì„ ìœ„í•´ ì ìˆ˜ ì €ì¥

    for i, score in enumerate(probs_list):
        if score >= 0.5:
            label_name = LABELS[i]
            detected_labels.append(label_name)
            label_scores[label_name] = score

    # 3. ìš•ì„¤ ì¹˜í™˜ ìˆ˜í–‰
    cleaned_text, replace_logs = replace_badwords_func(text)

    # 4. ë§ì¶¤í˜• í”¼ë“œë°± ì„ ì •
    # ê°ì§€ëœ í˜ì˜¤ ë¼ë²¨ ì¤‘ 'ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€' ë¼ë²¨ì˜ í”¼ë“œë°±ì„ ëŒ€í‘œë¡œ ë³´ì—¬ì¤Œ
    main_feedback = ""

    # cleanì´ ì•„ë‹ˆë©´ì„œ ê°ì§€ëœ ë¼ë²¨ì´ ìˆëŠ” ê²½ìš°
    hate_labels = [l for l in detected_labels if l != "clean"]

    if hate_labels:
        # í˜ì˜¤ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ë¼ë²¨ ì°¾ê¸°
        top_label = max(hate_labels, key=lambda l: label_scores[l])
        main_feedback = FEEDBACK_DICT.get(top_label, "ìƒëŒ€ë¥¼ ì¡´ì¤‘í•˜ëŠ” ê³ ìš´ ë§ì„ ì¨ì£¼ì„¸ìš”.")
    elif "clean" in detected_labels:
        main_feedback = FEEDBACK_DICT["clean"]
    else:
        # ì•„ë¬´ê²ƒë„ ê°ì§€ë˜ì§€ ì•Šì•˜ê±°ë‚˜(Threshold ë¯¸ë§Œ) ì• ë§¤í•œ ê²½ìš°
        detected_labels.append("ì •ìƒ(Clean)")
        main_feedback = FEEDBACK_DICT["clean"]

    return {
        "original": text,
        "cleaned": cleaned_text,
        "labels": detected_labels,
        "replace_logs": replace_logs,
        "feedback": main_feedback
    }


# =============================================================================
# 3. ë©”ì¸ ì‹¤í–‰ ë£¨í”„ (ë°ëª¨ UI)
# =============================================================================

def run_demo():
    # ëª¨ë¸ ë¡œë“œ
    model, tokenizer, device = load_system()

    print("\n" + "=" * 70)
    print("      [ ê¸°ê³„í•™ìŠµ 8ì¡°: ë¬¸ë§¥ ê¸°ë°˜ ì‹¤ì‹œê°„ í˜ì˜¤ í‘œí˜„ ë‹¤ì¤‘ ë¶„ë¥˜ ì‹œìŠ¤í…œ ]")
    print("=" * 70)
    print(" â€» ì¢…ë£Œí•˜ë ¤ë©´ 'q' ë˜ëŠ” 'exit'ì„ ì…ë ¥í•˜ì„¸ìš”.\n")

    while True:
        try:
            # ì‚¬ìš©ì ì…ë ¥
            print("-" * 70)
            user_input = input("ğŸ“ ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”: ")

            # ì¢…ë£Œ ì¡°ê±´
            if user_input.strip().lower() in ['q', 'exit', 'quit']:
                print("\n[ì‹œìŠ¤í…œ] ë°ëª¨ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤.")
                break

            # ë¹ˆ ì…ë ¥ ì²˜ë¦¬
            if not user_input.strip():
                continue

            # ë¶„ì„ ìˆ˜í–‰
            result = analyze_sentence(user_input, model, tokenizer, device)

            # --- ê²°ê³¼ ì¶œë ¥ í™”ë©´ (ê°€ë…ì„± ìµœì í™”) ---
            print("\n   [ ë¶„ì„ ê²°ê³¼ ]")

            # 1. ì›ë¬¸
            print(f"   â–¶ ì›ë¬¸ ë¬¸ì¥ :  {result['original']}")

            # 2. ìˆœí™” (ì¹˜í™˜ëœ ê²½ìš°ì—ë§Œ í‘œì‹œ)
            if result['replace_logs']:
                print(f"   â–¶ ìˆœí™” ë¬¸ì¥ :  {result['cleaned']}")
                print(f"   â–¶ ì¹˜í™˜ ë‚´ì—­ :  {', '.join(result['replace_logs'])}")
            else:
                print(f"   â–¶ ìˆœí™” ë¬¸ì¥ :  (ë³€ë™ ì‚¬í•­ ì—†ìŒ)")

            # 3. ê°ì§€ ìœ í˜•
            # ë¦¬ìŠ¤íŠ¸ë¥¼ ë³´ê¸° ì¢‹ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜
            labels_str = ", ".join(result['labels'])
            print(f"   â–¶ ê°ì§€ ìœ í˜• :  [{labels_str}]")

            # 4. AI í”¼ë“œë°±
            print(f"   â–¶ AI í”¼ë“œë°± :  \"{result['feedback']}\"")
            print("")  # ê³µë°± ë¼ì¸

        except KeyboardInterrupt:
            print("\n\n[ì‹œìŠ¤í…œ] ê°•ì œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"\n[ì˜¤ë¥˜] ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


if __name__ == "__main__":
    run_demo()
